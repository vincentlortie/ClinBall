{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing into a single dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat shape (44399, 3)\n",
      "shape before (44399, 3)\n",
      "shape after dropping all data with score = '.' (44399, 3)\n",
      "['Pathogenic', 'Likely_pathogenic', 'Pathogenic/Likely_pathogenic', 'Benign/Likely_benign', 'Likely_benign', 'Benign']\n",
      "                    Polyphen2_HVAR_score          clinvar_clnsig  position\n",
      "chr pos     ref alt                                                       \n",
      "2   272223  G   A                      0  Uncertain_significance    272223\n",
      "                A                      0  Uncertain_significance    272223\n",
      "    277003  A   G                  0.003                  Benign    277003\n",
      "    1436306 C   A                  0.992  Uncertain_significance   1436306\n",
      "    1436345 C   T                      0  Uncertain_significance   1436345\n",
      "DF SHAPE (13825, 3)\n",
      "                    Polyphen2_HVAR_score        clinvar_clnsig  position\n",
      "chr pos     ref alt                                                     \n",
      "2   277003  A   G                  0.003                Benign    277003\n",
      "    1456232 G   T                  0.065  Benign/Likely_benign   1456232\n",
      "    1477383 G   T                  0.007  Benign/Likely_benign   1477383\n",
      "    1477459 G   C                  0.965                Benign   1477459\n",
      "    1484596 A   T                  0.967            Pathogenic   1484596\n",
      "shape after dropping Unk (13825, 3)\n",
      "                    Polyphen2_HVAR_score  position  Problematic\n",
      "chr pos     ref alt                                            \n",
      "2   277003  A   G                  0.003    277003            0\n",
      "    1456232 G   T                  0.065   1456232            0\n",
      "    1477383 G   T                  0.007   1477383            0\n",
      "    1477459 G   C                  0.965   1477459            0\n",
      "    1484596 A   T                  0.967   1484596            1\n",
      "TOTAL SUM OF LABELS: \n",
      " 1    9865\n",
      "0    3960\n",
      "Name: Problematic, dtype: int64\n",
      "PERCENT OF LABELS: \n",
      " 1    0.713562\n",
      "0    0.286438\n",
      "Name: Problematic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas\n",
    "import pandas as pd\n",
    "'''\n",
    "Baseline with Polyphen\n",
    "\n",
    "### MK used:\n",
    "for i in 2 3 4; do python3 keep_relevant_headers.py ../data/chr2-4_with_gene/chr$i\\_gene.tsv \\\n",
    "../data/chr2-4_with_gene/chr$i.polyphen.tsv --cols chr,pos,ref,alt,Polyphen2_HVAR_pred,clinvar_clnsig\\; done\n",
    "\n",
    "'''\n",
    "\n",
    "df_all = pd.read_csv('../../../data/chr2-4_with_gene/chr2.polyphen.tsv', sep='\\t', encoding = \"UTF-8\")\n",
    "df_all['position'] = df_all['pos']\n",
    "df_all = df_all.set_index(['chr','pos', 'ref', 'alt']) #index by identifier\n",
    "\n",
    "for c in range (3,5):\n",
    "    path = '../../../data/chr2-4_with_gene/chr' + str(c) + '.polyphen.tsv'\n",
    "    df = pd.read_csv(path, sep='\\t', encoding = \"UTF-8\")\n",
    "    df['position'] = df['pos']\n",
    "    df = df.set_index(['chr','pos', 'ref', 'alt']) #index by identifier\n",
    "    df_all= df_all.append(df)\n",
    "    \n",
    "print('concat shape', df_all.shape)\n",
    "\n",
    "df = df_all\n",
    "print(\"shape before\", df.shape)\n",
    "df = df.replace({'.': 0})  ## FIXME: atm replace with nan and drop: later find a way to impute, maybe 0 but not sure\n",
    "#print(\"SUM\", pd.isnull(df).sum())  ## Use this to see how many elements have nan \n",
    "df = df.dropna()\n",
    "print(\"shape after dropping all data with score = '.'\", df.shape)\n",
    "## still contains some mixed labels, see them by: df[~df['clinvar_clnsig'].isin(list(clinvar_labels.keys()))]\n",
    "\n",
    "### prior to remapping of clinical significance labels to only pathogenic/benign, check out the distirbutions:\n",
    "#print(\"TOTAL SUM OF clinsig: \\n\", df['clinvar_clnsig'].value_counts())\n",
    "#print(\"PERCENT OF clinsig: \\n\", df['clinvar_clnsig'].value_counts(normalize=True))\n",
    "#print(\"CLINVAR LABELS \\n\", df.groupby('clinvar_clnsig').count())\n",
    "\n",
    "\n",
    "features_mapping = {\n",
    "    'Polyphen2_HVAR_pred': {\n",
    "        'D': -2,\n",
    "        'P': -1, \n",
    "        'B': 1\n",
    "    },\n",
    "    'Ancestral_allele': {\n",
    "        'A': 2,\n",
    "        'C': 2,\n",
    "        'T': 2,\n",
    "        'G': 2,\n",
    "        'a': 1,\n",
    "        'c': 1,\n",
    "        't': 1,\n",
    "        'g': 1,\n",
    "        'N': 1,\n",
    "        '-': -2,\n",
    "    },\n",
    "    'Essential_gene_CRISPR': {\n",
    "        'E': -1,\n",
    "        'N': 1\n",
    "    }\n",
    "}\n",
    "## Map labels to 1/0 and remove Unkn\n",
    "clinvar_labels={\n",
    "    'Pathogenic': 1,\n",
    "    'Likely_pathogenic': 1,\n",
    "    'Pathogenic/Likely_pathogenic': 1,\n",
    "    'Benign/Likely_benign': 0,\n",
    "    'Likely_benign': 0,\n",
    "    'Benign': 0\n",
    "}\n",
    "\n",
    "df = df.replace(features_mapping)\n",
    "#print(\"DF SHAPE\", df.shape)\n",
    "print(list(clinvar_labels.keys()))\n",
    "print(df.head())\n",
    "df = df[df['clinvar_clnsig'].isin(list(clinvar_labels.keys()))]  # best to drop everything that isn't in the dict\n",
    "\n",
    "print(\"DF SHAPE\", df.shape)\n",
    "print(df.head())\n",
    "df['Problematic'] = df['clinvar_clnsig'].map(clinvar_labels)\n",
    "\n",
    "df= df.drop(columns=['clinvar_clnsig'])#, 'clinvar_id'])  #tbh, I don't know why I kept them. consider adding to index\n",
    "print(\"shape after dropping Unk\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "#print(\"PROBLEMATIC LABEL DISTRIBUTION \\n\", df.groupby('Problematic').count())\n",
    "print(\"TOTAL SUM OF LABELS: \\n\", df['Problematic'].value_counts())\n",
    "print(\"PERCENT OF LABELS: \\n\", df['Problematic'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the follow is the addition of mutational counts columns\n",
    "* Note that the various kb ranges are selected to span a wide range of resolutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pickle to reuse dataframe:\n",
    "df = df.drop(columns=['position'])\n",
    "df.to_pickle(\"../pickled/chr2-4_polyphen.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
