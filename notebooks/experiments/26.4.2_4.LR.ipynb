{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature set 4 chromosomes 2, 3, 4 \n",
    "\n",
    "## In this notebook:\n",
    "\n",
    "* single input dataframe \n",
    "* using feature set 4 \n",
    "* GradientBoostingClassifier \n",
    "* only training/test split, no epochs \n",
    "* aucuracy assessement : \n",
    "* feature importance for RF (mostly just amino acid position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before (13820, 15)\n",
      "shape after dropping all data with score = '.' (13820, 15)\n",
      "shape after dropping Unk (13820, 15)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# using sklearn goodies\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "\n",
    "## pull in pickled dataframe:\n",
    "df = pd.read_pickle(\"./pickled/chr2-4_featureset4.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"shape before\", df.shape)\n",
    "df = df.replace({'.': 0})  ## FIXME: atm replace with nan and drop: later find a way to impute, maybe 0 but not sure\n",
    "#print(\"SUM\", pd.isnull(df).sum())  ## Use this to see how many elements have nan \n",
    "df = df.dropna()\n",
    "print(\"shape after dropping all data with score = '.'\", df.shape)\n",
    "#print(df.head())\n",
    "\n",
    "## still contains some mixed labels, see them by: df[~df['clinvar_clnsig'].isin(list(clinvar_labels.keys()))]\n",
    "\n",
    "## Map labels to 1/0 and remove Unkn\n",
    "clinvar_labels={\n",
    "    'Pathogenic': 1,\n",
    "    'Likely_pathogenic': 1,\n",
    "    'Pathogenic/Likely_pathogenic': 1,\n",
    "    'Benign/Likely_benign': 0,\n",
    "    'Likely_benign': 0,\n",
    "    'Benign': 0\n",
    "}\n",
    "\n",
    "#df.head()\n",
    "#df = df[df['clinvar_clnsig'].isin(list(clinvar_labels.keys()))]  # best to drop everything that isn't in the dict\n",
    "#df['Problematic'] = df['clinvar_clnsig'].map(clinvar_labels)\n",
    "\n",
    "#df= df.drop(columns=['clinvar_clnsig'])#, 'clinvar_id'])  #tbh, I don't know why I kept them. consider adding to index\n",
    "\n",
    "df = df.replace({'-': 0}) \n",
    "print(\"shape after dropping Unk\", df.shape)\n",
    "#df.head()\n",
    "\n",
    "### pickle to reuse dataframe:\n",
    "#df.to_pickle(\"./pickled_df/all_scores_chr18,20.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data subset\n",
      "\n",
      "                       aapos codonpos  Ancestral_allele  Polyphen2_HVAR_pred  \\\n",
      "chr pos       ref alt                                                          \n",
      "2   222220292 G   A      341        1                 2                    0   \n",
      "4   95114733  T   C       53        1                 2                   -2   \n",
      "2   178694626 C   T    10150        1                 2                    0   \n",
      "\n",
      "                        GenoCanyon_score HUVEC_fitCons_score  \\\n",
      "chr pos       ref alt                                          \n",
      "2   222220292 G   A    0.999999999414244            0.564101   \n",
      "4   95114733  T   C    0.999999997815507              0.6691   \n",
      "2   178694626 C   T    0.999728534038663            0.542086   \n",
      "\n",
      "                            ExAC_cnv.score  SORVA_LOF_MAF0.005_HetOrHom  \\\n",
      "chr pos       ref alt                                                     \n",
      "2   222220292 G   A       1.41369465212203                     0.001198   \n",
      "4   95114733  T   C    -0.0678400328187906                     0.001198   \n",
      "2   178694626 C   T                      0                     0.017173   \n",
      "\n",
      "                       Essential_gene_CRISPR  Problematic  Mutation<1kb  \\\n",
      "chr pos       ref alt                                                     \n",
      "2   222220292 G   A                        1            1             3   \n",
      "4   95114733  T   C                        1            1             1   \n",
      "2   178694626 C   T                        1            0             2   \n",
      "\n",
      "                       Mutation<5kb  Mutation<10kb  Mutation<30kb  \\\n",
      "chr pos       ref alt                                               \n",
      "2   222220292 G   A               6              6             18   \n",
      "4   95114733  T   C               2              4             12   \n",
      "2   178694626 C   T               7             18             98   \n",
      "\n",
      "                       Mutation<100kb  \n",
      "chr pos       ref alt                  \n",
      "2   222220292 G   A                41  \n",
      "4   95114733  T   C                16  \n",
      "2   178694626 C   T               486  \n",
      "\n",
      "Test data subset\n",
      "\n",
      "                     aapos codonpos  Ancestral_allele  Polyphen2_HVAR_pred  \\\n",
      "chr pos     ref alt                                                          \n",
      "2   277003  A   G      106        2                 2                    1   \n",
      "    1477383 G   T      373        1                 2                    1   \n",
      "    1496098 A   G      706        1                 2                    1   \n",
      "\n",
      "                        GenoCanyon_score HUVEC_fitCons_score  \\\n",
      "chr pos     ref alt                                            \n",
      "2   277003  A   G        0.9777236555582            0.714379   \n",
      "    1477383 G   T    0.00235440757137344            0.613276   \n",
      "    1496098 A   G      0.999995654489285            0.613276   \n",
      "\n",
      "                        ExAC_cnv.score  SORVA_LOF_MAF0.005_HetOrHom  \\\n",
      "chr pos     ref alt                                                   \n",
      "2   277003  A   G    -1.38628707843331                     0.000399   \n",
      "    1477383 G   T    -2.47162789907313                     0.004792   \n",
      "    1496098 A   G    -2.47162789907313                     0.004792   \n",
      "\n",
      "                     Essential_gene_CRISPR  Problematic  Mutation<1kb  \\\n",
      "chr pos     ref alt                                                     \n",
      "2   277003  A   G                        1            0             1   \n",
      "    1477383 G   T                        1            0             2   \n",
      "    1496098 A   G                        1            0             4   \n",
      "\n",
      "                     Mutation<5kb  Mutation<10kb  Mutation<30kb  \\\n",
      "chr pos     ref alt                                               \n",
      "2   277003  A   G               1              1              1   \n",
      "    1477383 G   T               2              5             18   \n",
      "    1496098 A   G               8             12             18   \n",
      "\n",
      "                     Mutation<100kb  \n",
      "chr pos     ref alt                  \n",
      "2   277003  A   G                 5  \n",
      "    1477383 G   T                19  \n",
      "    1496098 A   G                19  \n"
     ]
    }
   ],
   "source": [
    "## Split into train/test\n",
    "data_copy = df.copy()\n",
    "df_train = data_copy.sample(frac=0.75, random_state=1)\n",
    "df_test = data_copy.drop(df_train.index)\n",
    "\n",
    "print ('Training data subset\\n')\n",
    "print (df_train.head(3))  # head default n=5, first 3 is enough\n",
    "print ('\\nTest data subset\\n')\n",
    "print (df_test.head(3))\n",
    "\n",
    "\n",
    "## Get label:\n",
    "train_labels = df_train.pop('Problematic')  # replace with clinvar when column is available\n",
    "test_labels = df_test.pop('Problematic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Try a random forest:\n",
    "\n",
    "#forest = GradientBoostingClassifier(n_estimators=1000, random_state=42)\n",
    "reg = LogisticRegression(class_weight='balanced', max_iter=1000).fit(df_train, train_labels)\n",
    "#ax = plt.gca()\n",
    "#rfc_disp = plot_roc_curve(reg, df_test, test_labels, ax=ax, alpha=0.8)\n",
    "#svc_disp.plot(ax=ax, alpha=0.8) ## if you want to plot both svm and rf\n",
    "#plt.show()\n",
    "\n",
    "## metrics:\n",
    "y_true = test_labels.to_numpy()\n",
    "y_pred = reg.predict(df_test)\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results of exp 11: n=10\n",
    "Confusion matrix: \n",
    " [[ 733  243]\n",
    " [ 251 2186]]\n",
    "Accuracy: 0.855259302666276\n",
    "Recall TP/(TP+FN): [0.75102459 0.89700451]\n",
    "Precision TP/(TP+FP): [0.7449187  0.89995883]\n",
    "F1: [0.74795918 0.89847924]\n",
    "\n",
    "### results of exp 16: n=10\n",
    "Confusion matrix: \n",
    " [[ 455  521]\n",
    " [ 101 2336]]\n",
    "Accuracy: 0.8177556401992382\n",
    "Recall TP/(TP+FN): [0.46618852 0.9585556 ]\n",
    "Precision TP/(TP+FP): [0.81834532 0.81764088]\n",
    "F1: [0.59399478 0.8825085 ]\n",
    "\n",
    "### results of exp 16: n=100\n",
    "Confusion matrix: \n",
    " [[ 585  391]\n",
    " [ 156 2281]]\n",
    "Accuracy: 0.8397304424260181\n",
    "Recall TP/(TP+FN): [0.59938525 0.93598687]\n",
    "Precision TP/(TP+FP): [0.78947368 0.85366766]\n",
    "F1: [0.68142108 0.89293404]\n",
    "\n",
    "### results of exp 16: n=1000\n",
    "Confusion matrix: \n",
    " [[ 681  295]\n",
    " [ 180 2257]]\n",
    "Accuracy: 0.8608262525637269\n",
    "Recall TP/(TP+FN): [0.6977459 0.9261387]\n",
    "Precision TP/(TP+FP): [0.79094077 0.88440439]\n",
    "F1: [0.74142624 0.90479054]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[ 746  230]\n",
      " [ 754 1683]]\n",
      "Accuracy: 0.7116905947846469\n",
      "Recall TP/(TP+FN): [0.76434426 0.6906032 ]\n",
      "Precision TP/(TP+FP): [0.49733333 0.87976999]\n",
      "F1: [0.60258481 0.7737931 ]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "\n",
    "# Recall\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_true, y_pred, average=None)\n",
    "print(\"Recall TP/(TP+FN):\", recall)\n",
    "\n",
    "# Precision\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_true, y_pred, average=None)\n",
    "print(\"Precision TP/(TP+FP):\",precision)\n",
    "\n",
    "\n",
    "# F1 score\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1:\", F1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment results\n",
    "logistic: \n",
    "    Confusion matrix: \n",
    " [[ 118  858]\n",
    " [  68 2369]]\n",
    "Accuracy: 0.7286844418400235\n",
    "Recall TP/(TP+FN): [0.12090164 0.97209684]\n",
    "Precision TP/(TP+FP): [0.6344086  0.73411838]\n",
    "F1: [0.20309811 0.8365113 ]\n",
    "\n",
    "logistic with balanced:\n",
    "Confusion matrix: \n",
    " [[ 746  230]\n",
    " [ 754 1683]]\n",
    "Accuracy: 0.7116905947846469\n",
    "Recall TP/(TP+FN): [0.76434426 0.6906032 ]\n",
    "Precision TP/(TP+FP): [0.49733333 0.87976999]\n",
    "F1: [0.60258481 0.7737931 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
