{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing into a single dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat shape (38383, 14)\n",
      "shape before (38383, 14)\n",
      "shape after dropping all data with score = '.' (0, 14)\n",
      "Empty DataFrame\n",
      "Columns: [aapos, APPRIS, TSL, codonpos, Ancestral_allele, ExAC_cnv.score, HUVEC_fitCons_score, clinvar_clnsig, Interpro_domain, ExAC_cnv.score.1, GDI, LoFtool_score, SORVA_LOF_MAF0.005_HetOrHom, Essential_gene_CRISPR]\n",
      "Index: []\n",
      "shape after dropping Unk (0, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "'''\n",
    "for i in 2 3 4; do python3 keep_relevant_headers.py \\\n",
    "../data/chr2-4_with_gene/chr$i\\_gene.tsv \\\n",
    "../data/chr2-4_with_gene/chr$i.out_set1.tsv \\\n",
    "--cols chr,pos,ref,alt,aapos,APPRIS,TSL,codonpos,Ancestral_allele,ExAC_cnv.score,\\\n",
    "HUVEC_fitCons_score,clinvar_clnsig,Interpro_domain,GDI,LoFtool_score,SORVA_LOF_MAF0.005_HetOrHom,\\\n",
    "Essential_gene_CRISPR; done\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "df_all = pd.read_csv('../data/chr2-4_with_gene/chr2.out_set1.tsv', sep='\\t', encoding = \"UTF-8\")\n",
    "df_all = df_all.set_index(['chr','pos', 'ref', 'alt']) #index by identifier\n",
    "\n",
    "for c in range (3,4):\n",
    "    #print(c)\n",
    "    path = '../data/chr2-4_with_gene/chr' + str(c) + '.out_set1.tsv'\n",
    "    df = pd.read_csv(path, sep='\\t', encoding = \"UTF-8\")\n",
    "    df = df.set_index(['chr','pos', 'ref', 'alt']) #index by identifier\n",
    "    df_all= df_all.append(df)\n",
    "    \n",
    "print('concat shape', df_all.shape)\n",
    "\n",
    "df = df_all\n",
    "print(\"shape before\", df.shape)\n",
    "#print(df.head)\n",
    "df = df.replace({'.': 0})  ## FIXME: atm replace with nan and drop: later find a way to impute, maybe 0 but not sure\n",
    "#print(\"SUM\", pd.isnull(df).sum())  ## Use this to see how many elements have nan \n",
    "df = df.dropna()\n",
    "print(\"shape after dropping all data with score = '.'\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "## still contains some mixed labels, see them by: df[~df['clinvar_clnsig'].isin(list(clinvar_labels.keys()))]\n",
    "\n",
    "## Map labels to 1/0 and remove Unkn\n",
    "clinvar_labels={\n",
    "    'Pathogenic': 1,\n",
    "    'Likely_pathogenic': 1,\n",
    "    'Pathogenic/Likely_pathogenic': 1,\n",
    "    'Benign/Likely_benign': 0,\n",
    "    'Likely_benign': 0,\n",
    "    'Benign': 0\n",
    "}\n",
    "\n",
    "#df.head()\n",
    "df = df[df['clinvar_clnsig'].isin(list(clinvar_labels.keys()))]  # best to drop everything that isn't in the dict\n",
    "df['Problematic'] = df['clinvar_clnsig'].map(clinvar_labels)\n",
    "\n",
    "df= df.drop(columns=['clinvar_clnsig'])#, 'clinvar_id'])  #tbh, I don't know why I kept them. consider adding to index\n",
    "\n",
    "print(\"shape after dropping Unk\", df.shape)\n",
    "#df.head()\n",
    "\n",
    "### pickle to reuse dataframe:\n",
    "df.to_pickle(\"./pickled_dfset1_chr234.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
