{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmOp5bSsLvO1"
   },
   "source": [
    "# Prelim ClinBall\n",
    "Notes on gettings started with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before (6016, 4)\n",
      "shape after (4442, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>FATHMM_score</th>\n",
       "      <th>MutationTaster_score</th>\n",
       "      <th>integrated_fitCons_score</th>\n",
       "      <th>GenoCanyon_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th>373410</th>\n",
       "      <th>A</th>\n",
       "      <th>T</th>\n",
       "      <td>1</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.0130497586673599</td>\n",
       "      <td>0.562547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373417</th>\n",
       "      <th>C</th>\n",
       "      <th>G</th>\n",
       "      <td>0.999992</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.0126382143136347</td>\n",
       "      <td>0.562547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373858</th>\n",
       "      <th>C</th>\n",
       "      <th>T</th>\n",
       "      <td>0.999887</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.00763682056905044</td>\n",
       "      <td>0.732398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500399</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <td>0.999112</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.999689656609204</td>\n",
       "      <td>0.542737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500405</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.999999998480455</td>\n",
       "      <td>0.542737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   FATHMM_score MutationTaster_score integrated_fitCons_score  \\\n",
       "chr pos    ref alt                                                              \n",
       "4   373410 A   T              1                 3.21       0.0130497586673599   \n",
       "    373417 C   G       0.999992                 1.28       0.0126382143136347   \n",
       "    373858 C   T       0.999887                 3.22      0.00763682056905044   \n",
       "    500399 C   A       0.999112                  3.2        0.999689656609204   \n",
       "    500405 C   A              1                 3.11        0.999999998480455   \n",
       "\n",
       "                   GenoCanyon_score  \n",
       "chr pos    ref alt                   \n",
       "4   373410 A   T           0.562547  \n",
       "    373417 C   G           0.562547  \n",
       "    373858 C   T           0.732398  \n",
       "    500399 C   A           0.542737  \n",
       "    500405 C   A           0.542737  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/chr4_out.tsv', sep='\\t', encoding = \"UTF-8\")\n",
    "df = df.set_index(['chr','pos', 'ref', 'alt']) #index by identifier\n",
    "#print(df)\n",
    "#print(df.to_string()) ## will print the whole dataframe\n",
    "#df.plot.hist()\n",
    "\n",
    "print(\"shape before\", df.shape)\n",
    "df['MutationTaster_score'] = df['MutationTaster_score'].replace({'.': np.nan})\n",
    "df = df.dropna()\n",
    "print(\"shape after\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data subset\n",
      "\n",
      "                      FATHMM_score MutationTaster_score  \\\n",
      "chr pos       ref alt                                     \n",
      "4   158682399 T   A              1                -3.87   \n",
      "    113355493 G   A       0.999996                -0.09   \n",
      "    523543    G   A       0.999326                 3.11   \n",
      "\n",
      "                      integrated_fitCons_score GenoCanyon_score  \n",
      "chr pos       ref alt                                            \n",
      "4   158682399 T   A          0.999988431774354         0.706298  \n",
      "    113355493 G   A          0.999998296604523         0.562547  \n",
      "    523543    G   A          0.999135531316917         0.706548  \n",
      "\n",
      "Test data subset\n",
      "\n",
      "                   FATHMM_score MutationTaster_score integrated_fitCons_score  \\\n",
      "chr pos    ref alt                                                              \n",
      "4   500405 C   G              1                 3.08        0.999999998480455   \n",
      "    507558 G   A         0.8858                  0.9        0.987598326979718   \n",
      "    508895 A   G       0.999938                 1.49        0.732941250068165   \n",
      "\n",
      "                   GenoCanyon_score  \n",
      "chr pos    ref alt                   \n",
      "4   500405 C   G           0.542737  \n",
      "    507558 G   A           0.706548  \n",
      "    508895 A   G           0.706548  \n"
     ]
    }
   ],
   "source": [
    "## Split into train/test\n",
    "\n",
    "data_copy = df.copy()\n",
    "df_train = data_copy.sample(frac=0.75, random_state=1)\n",
    "df_test = data_copy.drop(df_train.index)\n",
    "\n",
    "print ('Training data subset\\n')\n",
    "print (df_train.head(3))  # head default n=5, first 3 is enough\n",
    "print ('\\nTest data subset\\n')\n",
    "print (df_test.head(3))\n",
    "\n",
    "\n",
    "## Get label: \n",
    "train_labels = df_train.pop('FATHMM_score')  # replace with clinvar when column is available\n",
    "test_labels = df_test.pop('FATHMM_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0053, 0.2097, 0.4987, 0.3685, 0.8900, 0.6237, 0.3274, 0.4972, 0.5356,\n",
      "        0.8351], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "### NOT NEEDED, WAS EXAMPLE\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# creating dummy targets (float values)\n",
    "targets_data = [random.random() for i in range(10)]\n",
    "\n",
    "# creating DataFrame from targets_data\n",
    "targets_df = pd.DataFrame(data=targets_data)\n",
    "targets_df.columns = ['targets']\n",
    "\n",
    "# creating tensor from targets_df \n",
    "torch_tensor = torch.tensor(targets_df['targets'].values)\n",
    "\n",
    "# printing out result\n",
    "print(torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tensor:\n",
      " tensor([[-3.8700,  1.0000,  0.7063],\n",
      "        [-0.0900,  1.0000,  0.5625],\n",
      "        [ 3.1100,  0.9991,  0.7065],\n",
      "        ...,\n",
      "        [-0.9500,  1.0000,  0.7065],\n",
      "        [-0.0500,  0.0063,  0.7063],\n",
      "        [-0.4600,  0.9996,  0.6155]])\n",
      "Test tensor: \n",
      " tensor([[ 3.0800,  1.0000,  0.5427],\n",
      "        [ 0.9000,  0.9876,  0.7065],\n",
      "        [ 1.4900,  0.7329,  0.7065],\n",
      "        ...,\n",
      "        [-2.2700,  0.0047,  0.4871],\n",
      "        [-2.8000,  0.0093,  0.4871],\n",
      "        [-2.3100,  0.3826,  0.4871]])\n",
      "torch.Size([64, 3])\n",
      "Line 1 tensor([0.9893, 0.9453, 0.9841, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9989, 0.6558, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9997, 1.0000, 1.0000, 1.0000, 1.0000, 0.9943, 1.0000, 0.9998,\n",
      "        1.0000, 1.0000, 0.5773, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9316,\n",
      "        0.9999, 0.9999, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9723, 1.0000, 1.0000, 1.0000, 0.9885, 0.9985, 0.9999,\n",
      "        0.9999, 0.8914, 1.0000, 1.0000, 1.0000, 1.0000, 0.9987, 1.0000, 1.0000,\n",
      "        1.0000])\n",
      "torch.Size([64, 3])\n",
      "Line 1 tensor([0.9980, 0.9462, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9998, 1.0000, 1.0000, 0.0376, 0.9993, 0.8208, 1.0000, 1.0000,\n",
      "        1.0000, 0.9986, 1.0000, 0.9979, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9999, 0.9992, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.8295, 1.0000, 1.0000, 1.0000, 0.0288, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5685, 1.0000, 0.8411, 0.9998,\n",
      "        0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 0.9956, 1.0000, 1.0000, 1.0000,\n",
      "        0.9990])\n"
     ]
    }
   ],
   "source": [
    "## Simple data import for train and testing datasets (if split), with pandas\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils import data as utils_data\n",
    "\n",
    "train_tensor = torch.tensor(df_train.values.astype(np.float32))\n",
    "train_labels_tensor = torch.tensor(train_labels.values.astype(np.float32))\n",
    "print(\"Train tensor:\\n\", train_tensor)\n",
    "                                     \n",
    "\n",
    "#test = pd.read_csv('data/chr4_out.tsv')\n",
    "test_tensor = torch.tensor(df_test.values.astype(np.float32))\n",
    "test_labels_tensor = torch.tensor(test_labels.values.astype(np.float32))\n",
    "print(\"Test tensor: \\n\", test_tensor)\n",
    "\n",
    "\n",
    "### Create your data loaders:\n",
    "train_X_y = utils_data.TensorDataset(train_tensor, train_labels_tensor)\n",
    "training_loader = utils_data.DataLoader(train_X_y, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "# not sure that these need to be seperate\n",
    "test_X_y = utils_data.TensorDataset(test_tensor, test_labels_tensor)\n",
    "testing_loader = utils_data.DataLoader(test_X_y, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "### Check your loader\n",
    "i1, l1 = next(iter(training_loader))\n",
    "print(i1.shape)\n",
    "print(\"Line 1\", l1)\n",
    "i2, l2 = next(iter(training_loader))\n",
    "print(i2.shape)\n",
    "print(\"Line 1\", l2)  ## should be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  With data processed: get started with pytorch by straight up copying MNIST example + modifying\n",
    "\n",
    "# Adapted from https://github.com/pytorch/examples/tree/master/mnist_hogwild \n",
    "from __future__ import print_function\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  # functions are defined, such as relu, softmax, dropout \n",
    "import torch.nn as nn  # wherre the layers are defined\n",
    "import torch.multiprocessing as mp\n",
    "# from torchvision import datasets, transforms  #note for MK: I should know what is vision specific and address that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64   # help='input batch size for training (default: 64)'\n",
    "test_batch_size = 1000   # help='input batch size for testing (default: 1000)'\n",
    "epochs = 10       # help='number of epochs to train (default: 10)'\n",
    "lr = 0.01         # help='learning rate (default: 0.01)'\n",
    "momentum = 0.5    # help='SGD momentum (default: 0.5)'\n",
    "seed = 1          # help='random seed (default: 1)'\n",
    "log_interval = 100 # help='how many batches to wait before logging training status'\n",
    "num_processes = 2 # help='how many training processes to use (default: 2)'\n",
    "cuda = False      # help='enables CUDA training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN --> not working bc of tensor size incompatability\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  ## is in_channel/out_channel the number of nodes? pretty sure yes\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)  \n",
    "        ## from this, the output chanels are 320, but you need to check the shape to know how to call the next layer\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1_drop = nn.Dropout()  #alt to F.dropout\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320) ## reshape to rearrange the data, MK does not understand quite how to get this value from their shapes\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.dropout(x, training=self.training)  # possible to use dropout object instead\n",
    "        x = self.fc1_drop(x)  # p default 0.5, inplate default False\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)  #log prob of each of the 10 classes/digits. not compatible with cross-entropy (log_softmax and nll)\n",
    "    \n",
    "    # note that if you want to use cross-entropy, use that instead of the nll below (and remove the above usage of log_softmax, instead forward would just return X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self, dim=200, input_size=100, output_size=10, num_layers=4):\n",
    "        super(mlp_generator, self).__init__()\n",
    "\n",
    "        num_layers = num_layers + 2  # add 2 for the 1st and the last layers\n",
    "        modules = []\n",
    "        for layer in range(num_layers): \n",
    "            in_size = input_size if layer == 0 else dim\n",
    "            out_size = output_size if layer == num_layers - 1 else dim\n",
    "            if layer < num_layers - 1:\n",
    "                modules.append(\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(in_size, out_size),\n",
    "                        nn.ReLU(True),\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                modules.append(\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(in_size, out_size),\n",
    "                        nn.Tanh()\n",
    "                    )\n",
    "                )\n",
    "        self.layers = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "## used: netG = mlp_generator(args.gen_dim, args.latent_dim, args.max_seq_len*vocab_size, args.gen_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "#use_cuda = cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\")  # torch.device(\"cuda\" if use_cuda else \"cpu\") # \n",
    "dataloader_kwargs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## don't run this, see what breaks\n",
    "torch.manual_seed(seed)\n",
    "#use_cuda = cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\")  # torch.device(\"cuda\" if use_cuda else \"cpu\") # \n",
    "dataloader_kwargs = {}# {'pin_memory': True} if use_cuda else {}  #maybe buggy, not clear if you need this \n",
    "\n",
    "\n",
    "##### These are the loaders for MNIST, we need to make our own\n",
    "train_loader_MNIST = torch.utils.data.DataLoader( \n",
    "    datasets.MNIST('./data', train=True, download=False,  # set download to True for first run\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=1, **dataloader_kwargs)\n",
    "\n",
    "\n",
    "test_loader_MNIST = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, download=False, # set download to True for first run\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=1, **dataloader_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)  # type of optimization algo\n",
    "\n",
    "model.conv1.weight   ## play with the model's methods and attributes\n",
    "## use tensor.shape is to check torch.Size \n",
    "print(model.conv1.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch,  1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 10 1 5 5, but got 2-dimensional input of size [64, 3] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c15c8f6af926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# set the gradients to zero to start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# loss is a tensor that is attached to the graph of computation, this is the tape that joseph talked about\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d624bfa1e501>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## reshape to rearrange the data, MK does not understand quite how to get this value from their shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 10 1 5 5, but got 2-dimensional input of size [64, 3] instead"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(\"epoch, \", epoch)\n",
    "    model.train()\n",
    "    pid = os.getpid()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(training_loader):\n",
    "        optimizer.zero_grad()  # set the gradients to zero to start\n",
    "        output = model(data.to(device))\n",
    "        \n",
    "        # loss is a tensor that is attached to the graph of computation, this is the tape that joseph talked about\n",
    "        loss = F.nll_loss(output, target.to(device))  #negative log-liklihood loss function (applied to one forward iteration)\n",
    "        # loss *= 0.1  ## Note: this would actually affect the gradient \n",
    "        val = loss.item() * 0.1  ## note that this would store the value, but not change it. Can look at detach for remove. \n",
    "        loss.backward() # calculate the gradients to see what to \"adjust\"\n",
    "        optimizer.step()  # use the gradients to update the weights\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('{}\\tTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                pid, epoch, batch_idx * len(data), len(training_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():  ## important not to add these gradients to the loss above (will affect model if you do)\n",
    "    for data, target in test_loader:\n",
    "        output = model(data.to(device))\n",
    "        # print(output)\n",
    "        test_loss += F.nll_loss(output, target.to(device), reduction='sum').item() # sum up batch loss\n",
    "        # print(test_loss)\n",
    "        pred = output.max(1)[1] # get the index of the max log-probability  \n",
    "        correct += pred.eq(target.to(device)).sum().item()  ## this is part of MNIST dataset, ours will be different. \n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "clinball.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
